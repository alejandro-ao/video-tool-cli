"""Unit tests for VideoProcessor content generation methods."""

import json
from pathlib import Path
from types import SimpleNamespace
from unittest.mock import Mock, patch

import pytest
from langchain_core.messages import AIMessage

from video_tool.video_processor import VideoProcessor
from tests.test_data.mock_generators import (
    MockVideoGenerator,
    MockTranscriptGenerator,
    MockDescriptionGenerator,
    MockTimestampGenerator,
    MockKeywordsGenerator
)
from tests.test_data.sample_data import (
    SAMPLE_GROQ_RESPONSE,
    SAMPLE_OPENAI_DESCRIPTION_RESPONSE,
    SAMPLE_OPENAI_KEYWORDS_RESPONSE,
    SAMPLE_VTT_CONTENT,
    SAMPLE_DESCRIPTION_MD,
    SAMPLE_KEYWORDS,
    SAMPLE_ERROR_RESPONSES,
    SAMPLE_LINKEDIN_POST,
    SAMPLE_TWITTER_POST
)


class TestGenerateTimestamps:
    """Test generate_timestamps method."""
    
    def test_generate_timestamps_with_processed_videos(self, temp_dir, mock_video_processor):
        """Test timestamp generation with processed videos."""
        # Create processed video files
        processed_dir = temp_dir / "processed"
        processed_files = MockVideoGenerator.create_test_video_set(processed_dir, count=3)
        output_dir = temp_dir / "output"
        
        mock_video_processor.video_dir = temp_dir
        
        # Mock video metadata
        with patch.object(mock_video_processor, '_get_video_metadata') as mock_metadata:
            mock_metadata.side_effect = [
                {'duration': 300.0},  # 5 minutes
                {'duration': 450.0},  # 7.5 minutes
                {'duration': 600.0}   # 10 minutes
            ]
            
            result = mock_video_processor.generate_timestamps()
            
            # Verify timestamps file was created
            timestamps_file = output_dir / "timestamps.json"
            assert timestamps_file.exists()
            
            # Verify content
            with open(timestamps_file, 'r') as f:
                timestamps_data = json.load(f)
            
            assert len(timestamps_data) == 1
            assert 'timestamps' in timestamps_data[0]
            assert len(timestamps_data[0]['timestamps']) == 3
            
            # Verify cumulative timing
            timestamps = timestamps_data[0]['timestamps']
            assert timestamps[0]['start'] == "00:00:00"
            assert timestamps[0]['end'] == "00:05:00"
            assert timestamps[1]['start'] == "00:05:00"
            assert timestamps[1]['end'] == "00:12:30"
            assert timestamps[2]['start'] == "00:12:30"
            assert timestamps[2]['end'] == "00:22:30"
    
    def test_generate_timestamps_fallback_to_original(self, temp_dir, mock_video_processor):
        """Test timestamp generation falls back to original videos when no processed videos."""
        # Create only original video files (no processed directory)
        video_files = MockVideoGenerator.create_test_video_set(temp_dir, count=2)
        output_dir = temp_dir / "output"
        
        mock_video_processor.video_dir = temp_dir
        
        with patch.object(mock_video_processor, '_get_video_metadata') as mock_metadata:
            mock_metadata.side_effect = [
                {'duration': 240.0},  # 4 minutes
                {'duration': 360.0}   # 6 minutes
            ]
            
            result = mock_video_processor.generate_timestamps()
            
            timestamps_file = output_dir / "timestamps.json"
            assert timestamps_file.exists()
            
            with open(timestamps_file, 'r') as f:
                timestamps_data = json.load(f)
            
            timestamps = timestamps_data[0]['timestamps']
            assert len(timestamps) == 2
            assert timestamps[0]['end'] == "00:04:00"
            assert timestamps[1]['end'] == "00:10:00"
    
    def test_generate_timestamps_no_videos(self, temp_dir, mock_video_processor):
        """Test timestamp generation with no video files."""
        mock_video_processor.video_dir = temp_dir
        
        with patch('video_tool.video_processor.logger') as mock_logger:
            result = mock_video_processor.generate_timestamps()
            
            # Should warn about no videos found
            mock_logger.warning.assert_called()
    
    def test_generate_timestamps_metadata_error(self, temp_dir, mock_video_processor):
        """Test timestamp generation when metadata extraction fails."""
        video_files = MockVideoGenerator.create_test_video_set(temp_dir, count=1)
        
        mock_video_processor.video_dir = temp_dir
        
        with patch.object(mock_video_processor, '_get_video_metadata') as mock_metadata:
            mock_metadata.return_value = None  # Simulate metadata failure
            
            with patch('video_tool.video_processor.logger') as mock_logger:
                result = mock_video_processor.generate_timestamps()
                
                # Should handle error gracefully
                mock_logger.assert_called()

    def test_generate_timestamps_refines_titles_with_transcript(
        self, temp_dir, mock_video_processor
    ):
        """Structured output should refine chapter titles using transcript excerpts."""
        processed_dir = temp_dir / "processed"
        MockVideoGenerator.create_test_video_set(processed_dir, count=2)
        transcript_file = temp_dir / "output" / "transcript.vtt"
        MockTranscriptGenerator.create_vtt_transcript(
            transcript_file,
            segments=[
                {"start": 0.0, "end": 60.0, "text": "Introduction to the tool and workflow."},
                {"start": 60.0, "end": 120.0, "text": "Project setup and configuration details."},
                {"start": 120.0, "end": 210.0, "text": "Deep dive into content generation routines."},
                {"start": 210.0, "end": 300.0, "text": "Best practices and final thoughts."},
            ],
        )

        mock_video_processor.video_dir = temp_dir

        with patch.object(mock_video_processor, '_get_video_metadata') as mock_metadata, patch.object(
            mock_video_processor, '_invoke_openai_chat_structured_output'
        ) as mock_structured:
            mock_metadata.side_effect = [
                {'duration': 120.0},
                {'duration': 180.0},
            ]

            mock_structured.return_value = SimpleNamespace(
                chapters=[
                    SimpleNamespace(start="00:00:00", end="00:02:00", title="Workflow Overview"),
                    SimpleNamespace(start="00:02:00", end="00:05:00", title="Content Generation Deep Dive"),
                ]
            )

            result = mock_video_processor.generate_timestamps()

        timestamps_file = temp_dir / "output" / "timestamps.json"
        assert timestamps_file.exists()

        data = json.loads(timestamps_file.read_text())
        assert data[0]['timestamps'][0]['title'] == "Workflow Overview"
        assert data[0]['timestamps'][1]['title'] == "Content Generation Deep Dive"
        mock_structured.assert_called_once()

    def test_generate_timestamps_structured_fallback_to_singles(
        self, temp_dir, mock_video_processor
    ):
        """If batch request fails, fallback per chapter still refines titles."""
        processed_dir = temp_dir / "processed"
        MockVideoGenerator.create_test_video_set(processed_dir, count=2)
        transcript_file = temp_dir / "output" / "transcript.vtt"
        MockTranscriptGenerator.create_vtt_transcript(
            transcript_file,
            segments=[
                {"start": 0.0, "end": 60.0, "text": "Intro segment here."},
                {"start": 60.0, "end": 120.0, "text": "Second chapter details."},
            ],
        )

        mock_video_processor.video_dir = temp_dir

        with patch.object(mock_video_processor, '_get_video_metadata') as mock_metadata, patch.object(
            mock_video_processor, '_invoke_openai_chat_structured_output'
        ) as mock_structured:
            mock_metadata.side_effect = [
                {'duration': 60.0},
                {'duration': 60.0},
            ]

            mock_structured.side_effect = [
                Exception("Length limit"),
                SimpleNamespace(
                    chapters=[
                        SimpleNamespace(start="00:00:00", end="00:01:00", title="Introduction Overview"),
                    ]
                ),
                SimpleNamespace(
                    chapters=[
                        SimpleNamespace(start="00:01:00", end="00:02:00", title="Deep Dive Topic"),
                    ]
                ),
            ]

            result = mock_video_processor.generate_timestamps()

        timestamps_file = temp_dir / "output" / "timestamps.json"
        assert timestamps_file.exists()

        data = json.loads(timestamps_file.read_text())
        assert data[0]['timestamps'][0]['title'] == "Introduction Overview"
        assert data[0]['timestamps'][1]['title'] == "Deep Dive Topic"
        assert mock_structured.call_count == 3

    def test_generate_timestamps_from_provided_transcript(
        self, temp_dir, mock_video_processor
    ):
        """Transcript flag should use the provided transcript and structured output."""
        transcript_file = temp_dir / "output" / "transcript.vtt"
        MockTranscriptGenerator.create_vtt_transcript(
            transcript_file,
            segments=[
                {"start": 0.0, "end": 120.0, "text": "Intro and context."},
                {"start": 120.0, "end": 420.0, "text": "Main content block with details."},
                {"start": 420.0, "end": 600.0, "text": "Wrap up and conclusion."},
            ],
        )

        with patch.object(mock_video_processor, "_invoke_openai_chat_structured_output") as mock_structured:
            mock_structured.return_value = SimpleNamespace(
                chapters=[
                    SimpleNamespace(start="0:00", title="Intro and Goals"),
                    SimpleNamespace(start="2:00", title="Deep Dive Section"),
                    SimpleNamespace(start="7:00", title="Recap and Next Steps"),
                ]
            )

            result = mock_video_processor.generate_timestamps(
                output_path=str(temp_dir / "output" / "timestamps.json"),
                transcript_path=str(transcript_file),
                stamps_from_transcript=True,
            )

        timestamps_file = temp_dir / "output" / "timestamps.json"
        assert timestamps_file.exists()

        data = json.loads(timestamps_file.read_text())
        timestamps = data[0]["timestamps"]
        assert timestamps[0]["start"] == "00:00:00"
        assert timestamps[1]["start"] == "00:02:00"
        assert timestamps[-1]["end"] == "00:10:00"
        assert data[0]["metadata"]["chapter_source"] == "transcript"
        assert data[0]["metadata"]["transcript_path"] == str(transcript_file)
        assert result["metadata"]["transcript_generated"] is False
        mock_structured.assert_called_once()

    def test_generate_timestamps_generates_transcript_when_missing(
        self, temp_dir, mock_video_processor
    ):
        """If no transcript path is supplied, the CLI flag triggers transcript creation."""
        transcript_file = temp_dir / "output" / "transcript.vtt"

        def _write_transcript(*args, **kwargs):
            MockTranscriptGenerator.create_vtt_transcript(
                transcript_file,
                segments=[
                    {"start": 0.0, "end": 180.0, "text": "Opening and overview."},
                    {"start": 180.0, "end": 420.0, "text": "Main topic discussion."},
                ],
            )
            return str(transcript_file)

        with patch.object(mock_video_processor, "generate_transcript", side_effect=_write_transcript) as mock_generate, patch.object(
            mock_video_processor, "_invoke_openai_chat_structured_output"
        ) as mock_structured:
            mock_structured.return_value = SimpleNamespace(
                chapters=[
                    SimpleNamespace(start="0:00", title="Introduction"),
                    SimpleNamespace(start="3:00", title="Main Topic"),
                ]
            )

            result = mock_video_processor.generate_timestamps(
                stamps_from_transcript=True,
            )

        timestamps_file = temp_dir / "output" / "timestamps.json"
        assert timestamps_file.exists()

        data = json.loads(timestamps_file.read_text())
        assert data[0]["timestamps"][1]["start"] == "00:03:00"
        assert data[0]["metadata"]["transcript_path"] == str(transcript_file)
        assert data[0]["metadata"]["transcript_generated"] is True
        mock_generate.assert_called_once()
        mock_structured.assert_called_once()

    def test_generate_timestamps_single_video_uses_provided_video_path(
        self, temp_dir, mock_video_processor
    ):
        """Ensure transcript generation uses the requested video when a single MP4 is provided."""
        video_file = temp_dir / "single.mp4"
        video_file.write_bytes(b"\x00\x00mockmp4")
        transcript_file = temp_dir / "output" / "transcript.vtt"

        def _write_transcript(video_path=None, output_path=None, **kwargs):
            assert video_path == str(video_file)
            MockTranscriptGenerator.create_vtt_transcript(
                Path(output_path),
                segments=[
                    {"start": 0.0, "end": 120.0, "text": "Intro content"},
                    {"start": 120.0, "end": 240.0, "text": "Main content"},
                ],
            )
            return str(output_path)

        with patch.object(mock_video_processor, "generate_transcript", side_effect=_write_transcript) as mock_generate, patch.object(
            mock_video_processor, "_invoke_openai_chat_structured_output"
        ) as mock_structured:
            mock_structured.return_value = SimpleNamespace(
                chapters=[
                    SimpleNamespace(start="0:00", title="Intro"),
                    SimpleNamespace(start="2:00", title="Main Section"),
                ]
            )

            result = mock_video_processor.generate_timestamps(
                video_path=str(video_file),
                stamps_from_transcript=True,
            )

        timestamps_file = temp_dir / "output" / "timestamps.json"
        assert timestamps_file.exists()
        data = json.loads(timestamps_file.read_text())
        assert data[0]["metadata"]["transcript_path"] == str(transcript_file)
        assert result["metadata"]["transcript_generated"] is True
        mock_generate.assert_called_once()
        mock_structured.assert_called_once()


class TestGenerateTranscript:
    """Test generate_transcript method."""
    
    @patch('groq.Groq')
    def test_generate_transcript_success(self, mock_groq_class, temp_dir, mock_video_processor):
        """Test successful transcript generation."""
        # Create concatenated video in output directory
        output_dir = temp_dir / "output"
        output_dir.mkdir(parents=True, exist_ok=True)
        video_file = output_dir / "concatenated_video.mp4"
        MockVideoGenerator.create_mock_mp4(video_file)
        
        # Mock Groq client
        mock_groq_instance = Mock()
        mock_groq_class.return_value = mock_groq_instance
        
        # Mock transcription response
        mock_response = Mock()
        mock_response.text = SAMPLE_GROQ_RESPONSE['text']
        mock_response.segments = SAMPLE_GROQ_RESPONSE['segments']
        
        mock_groq_instance.audio.transcriptions.create.return_value = mock_response
        
        mock_video_processor.video_dir = temp_dir
        mock_video_processor.groq = mock_groq_instance
        
        with patch('video_tool.video_processor.VideoFileClip') as mock_video_clip, \
             patch.object(mock_video_processor, '_groq_verbose_json_to_vtt') as mock_vtt_converter, \
             patch('os.path.getsize') as mock_getsize:
            # Mock audio extraction
            mock_clip = Mock()
            mock_audio = Mock()
            mock_clip.audio = mock_audio
            mock_video_clip.return_value = mock_clip
            
            # Mock file size to be under 25MB limit
            mock_getsize.return_value = 20 * 1024 * 1024  # 20MB
            
            # Mock VTT conversion to return expected content
            mock_vtt_converter.return_value = SAMPLE_VTT_CONTENT
            
            # Create the audio file with content to simulate successful extraction
            audio_file = video_file.with_suffix(".mp3")  # Use the same path as video but with .mp3 extension
            # Create a large file (simulate > 25MB) by writing a lot of content
            large_content = "mock audio content " * 1000000  # Create a large string
            audio_file.write_text(large_content)
            
            try:
                result = mock_video_processor.generate_transcript(str(video_file))
                print(f"DEBUG: Test result: {result}")
            except Exception as e:
                print(f"DEBUG: Exception in test: {e}")
                raise
            
            # Verify transcript file was created
            transcript_file = output_dir / "transcript.vtt"
            assert transcript_file.exists()
            
            # Verify Groq API was called
            mock_groq_instance.audio.transcriptions.create.assert_called_once()
    
    @patch('groq.Groq')
    def test_generate_transcript_small_file(self, mock_groq_class, temp_dir, mock_video_processor):
        """Test transcript generation with small file (no chunking needed)."""
        video_file = temp_dir / "output" / "concatenated_video.mp4"
        MockVideoGenerator.create_mock_mp4(video_file)
        output_dir = temp_dir / "output"
        
        mock_groq_instance = Mock()
        mock_groq_class.return_value = mock_groq_instance
        
        # Mock single response for small file
        mock_groq_instance.audio.transcriptions.create.return_value = Mock(
            text="Test transcript", 
            segments=SAMPLE_GROQ_RESPONSE['segments']
        )
        
        mock_video_processor.video_dir = temp_dir
        mock_video_processor.groq = mock_groq_instance
        
        with patch('video_tool.video_processor.VideoFileClip') as mock_video_clip, \
             patch.object(mock_video_processor, '_groq_verbose_json_to_vtt') as mock_vtt_converter, \
             patch('os.path.getsize') as mock_getsize:

            # Mock small audio file (â‰¤25MB)
            mock_clip = Mock()
            mock_audio = Mock()
            mock_audio.duration = 600  # 10 minutes - small file
            mock_clip.audio = mock_audio
            mock_clip.close = Mock()
            mock_video_clip.return_value = mock_clip

            # Mock audio write operation
            mock_audio.write_audiofile = Mock()

            # Create the audio file to simulate successful extraction (non-empty)
            audio_file = video_file.with_suffix(".mp3")
            audio_file.write_bytes(b'\x00' * 100)  # Write some bytes to avoid empty file check

            # Mock file size to be small (â‰¤25MB) - no chunking needed
            mock_getsize.return_value = 20 * 1024 * 1024  # 20MB

            # Mock VTT conversion
            mock_vtt_converter.return_value = SAMPLE_VTT_CONTENT

            result = mock_video_processor.generate_transcript(str(video_file))
            
            # Should call transcription once for small file
            assert mock_groq_instance.audio.transcriptions.create.call_count == 1
            
            # Verify the result is the expected VTT file path
            expected_output = str(output_dir / "transcript.vtt")
            assert result == expected_output

    @patch('groq.Groq')
    def test_generate_transcript_large_file_chunking(self, mock_groq_class, temp_dir, mock_video_processor):
        """Test transcript generation with large file chunking."""
        video_file = temp_dir / "output" / "concatenated_video.mp4"
        MockVideoGenerator.create_mock_mp4(video_file)
        output_dir = temp_dir / "output"
        
        mock_groq_instance = Mock()
        mock_groq_class.return_value = mock_groq_instance
        
        # Mock multiple chunk responses
        chunk_responses = [
            Mock(text="First chunk text", segments=SAMPLE_GROQ_RESPONSE['segments'][:1]),
            Mock(text="Second chunk text", segments=SAMPLE_GROQ_RESPONSE['segments'][1:2])
        ]
        
        mock_groq_instance.audio.transcriptions.create.side_effect = chunk_responses
        mock_video_processor.video_dir = temp_dir
        # Ensure the groq instance is properly set
        mock_video_processor.groq = mock_groq_instance
         
        with patch('video_tool.video_processor.VideoFileClip') as mock_video_clip, \
             patch('video_tool.video_processor.AudioSegment') as mock_audio_segment, \
             patch.object(mock_video_processor, '_groq_verbose_json_to_vtt') as mock_vtt_converter, \
             patch.object(mock_video_processor, '_clean_vtt_transcript') as mock_clean_vtt, \
             patch.object(mock_video_processor, '_merge_vtt_transcripts') as mock_merge, \
             patch('os.path.getsize') as mock_getsize:

            # Mock large audio file that needs chunking (>25MB)
            mock_clip = Mock()
            mock_audio = Mock()
            mock_audio.duration = 3600  # 1 hour - should trigger chunking
            mock_clip.audio = mock_audio
            mock_clip.close = Mock()
            mock_video_clip.return_value = mock_clip

            # Mock audio write operation
            mock_audio.write_audiofile = Mock()

            # Create the audio file to simulate successful extraction
            audio_file = video_file.with_suffix(".mp3")
            audio_file.write_bytes(b'\x00' * 100)  # Write some bytes to avoid empty file check

            # Mock file size to be large (>25MB) to trigger chunking
            mock_getsize.return_value = 30 * 1024 * 1024  # 30MB

            # Mock AudioSegment for chunking
            mock_audio_instance = Mock()
            # Configure the mock to support len() operation
            type(mock_audio_instance).__len__ = Mock(return_value=1200000)  # 20 minutes (2 chunks of 10 min each)
            mock_audio_segment.from_mp3.return_value = mock_audio_instance

            # Mock chunk creation and export
            mock_chunk = Mock()
            def create_chunk_file(path, format=None):
                # Create non-empty chunk file when export is called
                chunk_path = Path(path)
                chunk_path.write_bytes(b'\x00' * 100)
            mock_chunk.export.side_effect = create_chunk_file
            # Configure the mock to support slicing operations
            type(mock_audio_instance).__getitem__ = Mock(return_value=mock_chunk)

            # Mock VTT conversion and cleaning
            mock_vtt_converter.return_value = "WEBVTT\n\n00:00:00.000 --> 00:00:05.000\nTest chunk\n"
            mock_clean_vtt.return_value = "WEBVTT\n\n00:00:00.000 --> 00:00:05.000\nTest chunk\n"
            mock_merge.return_value = SAMPLE_VTT_CONTENT

            result = mock_video_processor.generate_transcript(str(video_file))
            
            # Should call transcription multiple times for chunks (2 chunks expected)
            assert mock_groq_instance.audio.transcriptions.create.call_count == 2
            
            # Verify the result is the expected VTT file path
            expected_output = str(output_dir / "transcript.vtt")
            assert result == expected_output
    
    @patch('groq.Groq')
    def test_generate_transcript_groq_error(self, mock_groq_class, temp_dir, mock_video_processor):
        """Test transcript generation when Groq API fails."""
        video_file = temp_dir / "output" / "concatenated_video.mp4"
        MockVideoGenerator.create_mock_mp4(video_file)
        
        mock_groq_instance = Mock()
        mock_groq_class.return_value = mock_groq_instance
        
        # Mock API error
        mock_groq_instance.audio.transcriptions.create.side_effect = Exception("API Error")
        
        mock_video_processor.video_dir = temp_dir
        mock_video_processor.groq = mock_groq_instance
        
        with patch('video_tool.video_processor.VideoFileClip'):
            with patch('video_tool.video_processor.logger') as mock_logger:
                video_file = temp_dir / "test_video.mp4"
                MockVideoGenerator.create_mock_mp4(video_file)  # Create the video file
                result = mock_video_processor.generate_transcript(str(video_file))
                
                # Should log the error
                mock_logger.error.assert_called()
    
    def test_generate_transcript_no_video_file(self, temp_dir, mock_video_processor):
        """Test transcript generation when concatenated video doesn't exist."""
        mock_video_processor.video_dir = temp_dir
        
        with patch('video_tool.video_processor.logger') as mock_logger:
            video_file = temp_dir / "nonexistent_video.mp4"
            result = mock_video_processor.generate_transcript(str(video_file))
            
            # Should log error about missing video file
            mock_logger.error.assert_called()
    
    def test_vtt_helper_methods(self, mock_video_processor):
        """Test VTT processing helper methods."""
        # Test VTT cleaning
        if hasattr(mock_video_processor, '_clean_vtt_transcript'):
            dirty_vtt = "WEBVTT\n\n00:00:00.000 --> 00:00:05.000\n[MUSIC] Hello world [APPLAUSE]\n\n"
            clean_vtt = mock_video_processor._clean_vtt_transcript(dirty_vtt)
            assert "[MUSIC]" not in clean_vtt
            assert "[APPLAUSE]" not in clean_vtt
        
        # Test Groq JSON to VTT conversion
        if hasattr(mock_video_processor, '_groq_verbose_json_to_vtt'):
            vtt_result = mock_video_processor._groq_verbose_json_to_vtt(SAMPLE_GROQ_RESPONSE)
            assert "WEBVTT" in vtt_result
            assert "00:00:00.000 --> 00:00:05.000" in vtt_result


class TestGenerateDescription:
    """Test generate_description method."""
    
    def test_generate_description_success(self, temp_dir, mock_video_processor):
        """Test successful description generation."""
        # Create transcript file
        transcript_file = temp_dir / "output" / "transcript.vtt"
        MockTranscriptGenerator.create_vtt_transcript(transcript_file)
        
        # Create timestamps file
        timestamps_file = temp_dir / "output" / "timestamps.json"
        MockTimestampGenerator.create_timestamps_json(timestamps_file, ["test_video.mp4"])
        
        mock_video_processor.video_dir = temp_dir

        # Mock OpenAI response
        with patch.object(mock_video_processor, '_invoke_openai_chat') as mock_invoke:
            # Mock both generation and polishing responses
            mock_invoke.side_effect = [
                AIMessage(content='Initial description'),
                AIMessage(
                    content=(
                        SAMPLE_OPENAI_DESCRIPTION_RESPONSE['choices'][0]['message']['content']
                    )
                ),
            ]

            # Create dummy paths for the test
            video_path = str(temp_dir / "test_video.mp4")
            repo_url = "https://github.com/test/repo"
            transcript_path = str(temp_dir / "output" / "transcript.vtt")

            # Create a dummy transcript file
            with open(transcript_path, 'w') as f:
                f.write("Test transcript content")

            result = mock_video_processor.generate_description(video_path, repo_url, transcript_path)

            # Verify description file was created
            description_file = temp_dir / "output" / "description.md"
            assert description_file.exists()

            # Verify OpenAI API was called twice (generation + polishing)
            assert mock_invoke.call_count == 2

            # Check that transcript was used in the first prompt (generation call)
            first_call_kwargs = mock_invoke.call_args_list[0].kwargs
            messages = first_call_kwargs['messages']
            assert any(
                isinstance(msg, dict) and 'transcript' in msg.get('content', '').lower()
                for msg in messages
            )
    
    def test_generate_description_with_polishing(self, temp_dir, mock_video_processor):
        """Test description generation with polishing step."""
        transcript_file = temp_dir / "output" / "transcript.vtt"
        MockTranscriptGenerator.create_vtt_transcript(transcript_file)
        
        # Create timestamps file
        timestamps_file = temp_dir / "output" / "timestamps.json"
        MockTimestampGenerator.create_timestamps_json(timestamps_file, ["test_video.mp4"])
        
        mock_video_processor.video_dir = temp_dir

        with patch.object(mock_video_processor, '_invoke_openai_chat') as mock_invoke:
            # Mock both generation and polishing responses
            mock_invoke.side_effect = [
                AIMessage(content='Initial description'),
                AIMessage(
                    content=(
                        SAMPLE_OPENAI_DESCRIPTION_RESPONSE['choices'][0]['message']['content']
                    )
                ),
            ]

            # Create dummy paths for the test
            video_path = str(temp_dir / "test_video.mp4")
            repo_url = "https://github.com/test/repo"
            transcript_path = str(temp_dir / "output" / "transcript.vtt")

            # Create a dummy transcript file
            with open(transcript_path, 'w') as f:
                f.write("Test transcript content")

            result = mock_video_processor.generate_description(video_path, repo_url, transcript_path)

            # Should call OpenAI twice (generation + polishing)
            assert mock_invoke.call_count == 2

            description_file = temp_dir / "output" / "description.md"
            assert description_file.exists()
    
    def test_generate_description_no_transcript(self, temp_dir, mock_video_processor):
        """Test description generation when transcript doesn't exist."""
        # Create timestamps file
        timestamps_file = temp_dir / "output" / "timestamps.json"
        MockTimestampGenerator.create_timestamps_json(timestamps_file, ["test_video.mp4"])
        
        mock_video_processor.video_dir = temp_dir
        
        with patch('video_tool.video_processor.logger') as mock_logger:
            # Create dummy paths for the test
            video_path = str(temp_dir / "test_video.mp4")
            repo_url = "https://github.com/test/repo"
            transcript_path = str(temp_dir / "output" / "transcript.vtt")
            
            # DO NOT create the transcript file - this is what we're testing
            
            result = mock_video_processor.generate_description(video_path, repo_url, transcript_path)
            
            # Should log error about missing transcript
            mock_logger.error.assert_called()
            # Should return empty string when transcript is missing
            assert result == ""
    
    def test_generate_description_openai_error(self, temp_dir, mock_video_processor):
        """Test description generation when OpenAI API fails."""
        transcript_file = temp_dir / "output" / "transcript.vtt"
        MockTranscriptGenerator.create_vtt_transcript(transcript_file)
        
        # Create timestamps file
        timestamps_file = temp_dir / "output" / "timestamps.json"
        MockTimestampGenerator.create_timestamps_json(timestamps_file, ["test_video.mp4"])
        
        mock_video_processor.video_dir = temp_dir
        
        with patch.object(mock_video_processor, '_invoke_openai_chat') as mock_invoke:
            mock_invoke.side_effect = Exception("OpenAI API Error")
            
            with patch('video_tool.video_processor.logger') as mock_logger:
                # Create dummy paths for the test
                video_path = str(temp_dir / "test_video.mp4")
                repo_url = "https://github.com/test/repo"
                transcript_path = str(temp_dir / "output" / "transcript.vtt")
                
                # Create a dummy transcript file
                with open(transcript_path, 'w') as f:
                    f.write("Test transcript content")
                
                # Expect the exception to be raised since there's no error handling
                with pytest.raises(Exception, match="OpenAI API Error"):
                    result = mock_video_processor.generate_description(video_path, repo_url, transcript_path)
    
    def test_generate_description_with_timestamps(self, temp_dir, mock_video_processor):
        """Test description generation includes timestamps."""
        # Create transcript and timestamps
        transcript_file = temp_dir / "output" / "transcript.vtt"
        timestamps_file = temp_dir / "output" / "timestamps.json"
        
        MockTranscriptGenerator.create_vtt_transcript(transcript_file)
        MockTimestampGenerator.create_timestamps_json(timestamps_file, ["video1.mp4", "video2.mp4"])
        
        mock_video_processor.video_dir = temp_dir
        
        with patch.object(mock_video_processor, '_invoke_openai_chat') as mock_invoke:
            mock_invoke.return_value = AIMessage(
                content=(
                    SAMPLE_OPENAI_DESCRIPTION_RESPONSE['choices'][0]['message']['content']
                )
            )
            
            # Create dummy paths for the test
            video_path = str(temp_dir / "test_video.mp4")
            repo_url = "https://github.com/test/repo"
            transcript_path = str(temp_dir / "output" / "transcript.vtt")
            
            # Create a dummy transcript file
            with open(transcript_path, 'w') as f:
                f.write("Test transcript content")
            
            result = mock_video_processor.generate_description(video_path, repo_url, transcript_path)
            
            description_file = temp_dir / "output" / "description.md"
            assert description_file.exists()
            
            # Verify timestamps were included in the description
            with open(description_file, 'r') as f:
                content = f.read()
                assert "00:00:00" in content or "Timestamps" in content


class TestGenerateSEOKeywords:
    """Test generate_seo_keywords method."""
    
    def test_generate_seo_keywords_success(self, temp_dir, mock_video_processor):
        """Test successful SEO keywords generation."""
        # Create description file
        description_file = temp_dir / "output" / "description.md"
        MockDescriptionGenerator.create_description_md(description_file)
        
        mock_video_processor.video_dir = temp_dir
        
        with patch.object(mock_video_processor, '_invoke_openai_chat') as mock_invoke:
            mock_invoke.return_value = AIMessage(
                content=SAMPLE_OPENAI_KEYWORDS_RESPONSE['choices'][0]['message']['content']
            )
            
            result = mock_video_processor.generate_seo_keywords(str(description_file))
            
            # Verify keywords file was created
            keywords_file = temp_dir / "output" / "keywords.txt"
            assert keywords_file.exists()
            
            # Verify content
            with open(keywords_file, 'r') as f:
                content = f.read()
                assert len(content.strip()) > 0
                assert ',' in content  # Should be comma-separated
            
            # Verify OpenAI API was called
            mock_invoke.assert_called_once()
    
    def test_generate_seo_keywords_no_description(self, temp_dir, mock_video_processor):
        """Test SEO keywords generation when description doesn't exist."""
        # Create timestamps file
        timestamps_file = temp_dir / "output" / "timestamps.json"
        MockTimestampGenerator.create_timestamps_json(timestamps_file, ["test_video.mp4"])
        
        mock_video_processor.video_dir = temp_dir
        
        # Create a non-existent description path to test error handling
        description_path = str(temp_dir / "output" / "nonexistent_description.md")
        
        with patch('video_tool.video_processor.logger') as mock_logger:
            result = mock_video_processor.generate_seo_keywords(description_path)
            
            # Should log error about missing description
            mock_logger.error.assert_called()
    
    def test_generate_seo_keywords_openai_error(self, temp_dir, mock_video_processor, mock_logger):
        """Test SEO keywords generation when OpenAI API fails."""
        description_file = temp_dir / "output" / "description.md"
        MockDescriptionGenerator.create_description_md(description_file)
        
        mock_video_processor.video_dir = temp_dir
        
        with patch.object(mock_video_processor, '_invoke_openai_chat') as mock_invoke:
            mock_invoke.side_effect = Exception("OpenAI API Error")
            
            # Should return empty string and log error instead of raising exception
            result = mock_video_processor.generate_seo_keywords(str(description_file))
            assert result == ""
            mock_logger.error.assert_called()
    
    def test_generate_seo_keywords_rate_limit_handling(self, temp_dir, mock_video_processor, mock_logger):
        """Test SEO keywords generation with rate limit handling."""
        description_file = temp_dir / "output" / "description.md"
        MockDescriptionGenerator.create_description_md(description_file)
        
        mock_video_processor.video_dir = temp_dir
        
        with patch.object(mock_video_processor, '_invoke_openai_chat') as mock_invoke:
            mock_invoke.side_effect = Exception("Rate limit exceeded")
            
            # Should return empty string and log error instead of raising exception
            result = mock_video_processor.generate_seo_keywords(str(description_file))
            assert result == ""
            mock_logger.error.assert_called()


class TestContentGenerationIntegration:
    """Integration tests for content generation workflow."""
    
    def test_complete_content_generation_workflow(self, temp_dir, mock_video_processor):
        """Test complete content generation from timestamps to keywords."""
        # Create initial video files
        video_files = MockVideoGenerator.create_test_video_set(temp_dir, count=2)
        processed_dir = temp_dir / "processed"
        processed_files = MockVideoGenerator.create_test_video_set(processed_dir, count=2)
        
        # Create concatenated video
        concat_video = temp_dir / "output" / "concatenated_video.mp4"
        MockVideoGenerator.create_mock_mp4(concat_video)
        
        # Create timestamps file
        timestamps_file = temp_dir / "output" / "timestamps.json"
        MockTimestampGenerator.create_timestamps_json(timestamps_file, ["test_video.mp4"])
        
        mock_video_processor.video_dir = temp_dir
        
        # Mock all external dependencies
        with patch.object(mock_video_processor, '_get_video_metadata') as mock_metadata, \
             patch.object(mock_video_processor.groq.audio.transcriptions, 'create') as mock_groq, \
             patch.object(mock_video_processor, '_invoke_openai_chat') as mock_openai, \
             patch('video_tool.video_processor.VideoFileClip'):
            
            # Setup mocks
            mock_metadata.return_value = {'duration': 300.0}
            
            mock_groq_response = Mock()
            mock_groq_response.text = SAMPLE_GROQ_RESPONSE['text']
            mock_groq_response.segments = SAMPLE_GROQ_RESPONSE['segments']
            mock_groq.return_value = mock_groq_response
            
            # Set up mock responses for multiple OpenAI calls (2 for description, 1 for keywords)
            description_response = AIMessage(
                content=SAMPLE_OPENAI_DESCRIPTION_RESPONSE['choices'][0]['message']['content']
            )
            polished_description_response = AIMessage(
                content="Polished: "
                + SAMPLE_OPENAI_DESCRIPTION_RESPONSE['choices'][0]['message']['content']
            )
            keywords_response = AIMessage(
                content=SAMPLE_OPENAI_KEYWORDS_RESPONSE['choices'][0]['message']['content']
            )
            mock_openai.side_effect = [description_response, polished_description_response, keywords_response]
            
            # Run complete workflow
            timestamps_result = mock_video_processor.generate_timestamps()
            transcript_result = mock_video_processor.generate_transcript()
            
            # Ensure transcript file exists for description generation
            transcript_file = temp_dir / "output" / "transcript.vtt"
            if not transcript_file.exists():
                MockTranscriptGenerator.create_vtt_file(transcript_file)
            
            description_result = mock_video_processor.generate_description()
            
            # Create a dummy description file for the test
            description_file = temp_dir / "output" / "description.md"
            MockDescriptionGenerator.create_description_md(description_file)
            keywords_result = mock_video_processor.generate_seo_keywords(str(description_file))
            
            # Verify all files were created
            assert (temp_dir / "output" / "timestamps.json").exists()
            assert (temp_dir / "output" / "transcript.vtt").exists()
            assert (temp_dir / "output" / "description.md").exists()
            assert (temp_dir / "output" / "keywords.txt").exists()
    
    def test_content_generation_error_recovery(self, temp_dir, mock_video_processor):
        """Test error recovery in content generation workflow."""
        # Create minimal setup
        video_files = MockVideoGenerator.create_test_video_set(temp_dir, count=1)
        concat_video = temp_dir / "output" / "concatenated_video.mp4"
        MockVideoGenerator.create_mock_mp4(concat_video)
        
        mock_video_processor.video_dir = temp_dir
        
        # Test partial failure scenario
        with patch.object(mock_video_processor, '_get_video_metadata') as mock_metadata, \
             patch.object(mock_video_processor.groq.audio.transcriptions, 'create') as mock_groq, \
             patch.object(mock_video_processor, '_invoke_openai_chat') as mock_openai, \
             patch('video_tool.video_processor.VideoFileClip'), \
             patch('video_tool.video_processor.logger') as mock_logger:
            
            # Setup mocks - some succeed, some fail
            mock_metadata.return_value = {'duration': 300.0}
            mock_groq.side_effect = Exception("Groq API Error")
            mock_openai.return_value = AIMessage(
                content=SAMPLE_OPENAI_DESCRIPTION_RESPONSE['choices'][0]['message']['content']
            )
            
            # Run workflow - should handle errors gracefully
            timestamps_result = mock_video_processor.generate_timestamps()
            transcript_result = mock_video_processor.generate_transcript()
            
            # Timestamps should succeed, transcript should fail
            assert (temp_dir / "output" / "timestamps.json").exists()
            assert not (temp_dir / "output" / "transcript.vtt").exists()
            
            # Should log errors
            mock_logger.error.assert_called()
    
    def test_file_dependencies_in_workflow(self, temp_dir, mock_video_processor):
        """Test that methods properly handle file dependencies."""
        # Create timestamps file
        timestamps_file = temp_dir / "output" / "timestamps.json"
        MockTimestampGenerator.create_timestamps_json(timestamps_file, ["test_video.mp4"])
        
        mock_video_processor.video_dir = temp_dir
        
        # Test description generation without transcript
        with patch('video_tool.video_processor.logger') as mock_logger:
            video_path = str(temp_dir / "test_video.mp4")
            repo_url = "https://github.com/test/repo"
            transcript_path = str(temp_dir / "output" / "nonexistent_transcript.vtt")
            description_result = mock_video_processor.generate_description(video_path, repo_url, transcript_path)
            mock_logger.error.assert_called()  # Should error about missing transcript
        
        # Test keywords generation without description
        with patch('video_tool.video_processor.logger') as mock_logger:
            description_path = str(temp_dir / "output" / "nonexistent_description.md")
            keywords_result = mock_video_processor.generate_seo_keywords(description_path)
            mock_logger.error.assert_called()  # Should error about missing description
        
        # Test transcript generation without concatenated video
        with patch('video_tool.video_processor.logger') as mock_logger:
            video_path = str(temp_dir / "nonexistent_video.mp4")
            transcript_result = mock_video_processor.generate_transcript(video_path)
            mock_logger.error.assert_called()  # Should error about missing video


class TestGenerateLinkedInPost:
    """Test generate_linkedin_post method."""
    
    def test_generate_linkedin_post_success(self, temp_dir, mock_video_processor):
        """Test successful LinkedIn post generation."""
        # Create transcript file
        transcript_file = temp_dir / "output" / "transcript.vtt"
        transcript_file.write_text(SAMPLE_VTT_CONTENT)
        
        mock_video_processor.input_dir = temp_dir
        
        # Mock OpenAI response
        with patch.object(mock_video_processor, '_invoke_openai_chat', return_value=AIMessage(content=SAMPLE_LINKEDIN_POST)):
            result = mock_video_processor.generate_linkedin_post(str(transcript_file))
            
            # Verify file was created
            linkedin_file = temp_dir / "output" / "linkedin_post.md"
            assert linkedin_file.exists()
            assert result == str(linkedin_file)
            
            # Verify content
            content = linkedin_file.read_text()
            assert "ðŸš€" in content  # Should contain emojis
            assert "#" in content   # Should contain hashtags
    
    def test_generate_linkedin_post_no_transcript(self, temp_dir, mock_video_processor):
        """Test LinkedIn post generation with missing transcript file."""
        mock_video_processor.input_dir = temp_dir
        
        with pytest.raises(FileNotFoundError):
            mock_video_processor.generate_linkedin_post(str(temp_dir / "nonexistent.vtt"))
    
    def test_generate_linkedin_post_openai_error(self, temp_dir, mock_video_processor, mock_logger):
        """Test LinkedIn post generation with OpenAI API error."""
        transcript_file = temp_dir / "output" / "transcript.vtt"
        transcript_file.write_text(SAMPLE_VTT_CONTENT)
        
        mock_video_processor.input_dir = temp_dir
        
        # Mock OpenAI error
        with patch.object(mock_video_processor, '_invoke_openai_chat', side_effect=Exception("API Error")):
            with pytest.raises(Exception, match="API Error"):
                mock_video_processor.generate_linkedin_post(str(transcript_file))


class TestGenerateTwitterPost:
    """Test generate_twitter_post method."""

    def test_generate_twitter_post_success(self, temp_dir, mock_video_processor):
        """Test successful Twitter post generation."""
        # Create transcript file
        transcript_file = temp_dir / "output" / "transcript.vtt"
        transcript_file.write_text(SAMPLE_VTT_CONTENT)
        
        mock_video_processor.input_dir = temp_dir
        
        # Mock OpenAI response
        with patch.object(mock_video_processor, '_invoke_openai_chat', return_value=AIMessage(content=SAMPLE_TWITTER_POST)):
            result = mock_video_processor.generate_twitter_post(str(transcript_file))
            
            # Verify file was created
            twitter_file = temp_dir / "output" / "twitter_post.md"
            assert twitter_file.exists()
            assert result == str(twitter_file)
            
            # Verify content
            content = twitter_file.read_text()
            assert len(content) <= 280  # Twitter character limit
            assert "#" in content       # Should contain hashtags
    
    def test_generate_twitter_post_no_transcript(self, temp_dir, mock_video_processor):
        """Test Twitter post generation with missing transcript file."""
        mock_video_processor.input_dir = temp_dir
        
        with pytest.raises(FileNotFoundError):
            mock_video_processor.generate_twitter_post(str(temp_dir / "nonexistent.vtt"))
    
    def test_generate_twitter_post_openai_error(self, temp_dir, mock_video_processor, mock_logger):
        """Test Twitter post generation with OpenAI API error."""
        transcript_file = temp_dir / "output" / "transcript.vtt"
        transcript_file.write_text(SAMPLE_VTT_CONTENT)
        
        mock_video_processor.input_dir = temp_dir

        # Mock OpenAI error
        with patch.object(mock_video_processor, '_invoke_openai_chat', side_effect=Exception("API Error")):
            with pytest.raises(Exception, match="API Error"):
                mock_video_processor.generate_twitter_post(str(transcript_file))


class TestGenerateSummary:
    """Tests for the transcript-to-summary step."""

    def _create_transcript(self, temp_dir: Path) -> Path:
        transcript_file = temp_dir / "output" / "transcript.vtt"
        transcript_file.write_text(
            "WEBVTT\n\n00:00:00.000 --> 00:00:01.000\nSample content.\n",
            encoding="utf-8",
        )
        return transcript_file

    def test_summary_skips_when_disabled(self, temp_dir: Path, mock_video_processor):
        """Configuration should allow bypassing summary generation."""

        transcript_file = self._create_transcript(temp_dir)

        with patch.object(mock_video_processor, "_invoke_openai_chat") as mock_chat:
            result = mock_video_processor.generate_summary(
                str(transcript_file), config={"enabled": False}
            )

        assert result == ""
        mock_chat.assert_not_called()

    def test_summary_generates_markdown_file(self, temp_dir: Path, mock_video_processor):
        """Markdown summaries should be saved to the summaries directory."""

        transcript_file = self._create_transcript(temp_dir)

        with patch.object(mock_video_processor, "_invoke_openai_chat") as mock_chat:
            mock_chat.return_value = AIMessage(content="# Summary\nBody text")

            summary_path = mock_video_processor.generate_summary(str(transcript_file))

        summary_file = Path(summary_path)
        assert summary_file.exists()
        assert summary_file.parent.name == "summaries"
        assert "Body text" in summary_file.read_text(encoding="utf-8")

    def test_summary_generates_json_payload(self, temp_dir: Path, mock_video_processor):
        """JSON output should follow the expected schema and omit keywords when disabled."""

        transcript_file = self._create_transcript(temp_dir)

        structured_response = SimpleNamespace(
            dict=lambda: {
                "what_this_video_is_about": "Overview",
                "why_this_topic_matters": "Impact",
                "key_points_covered": ["a", "b", "c", "d"],
                "what_is_built": "Pipeline",
                "actionable_insights": ["configure", "deploy"],
                "who_this_video_is_for": "Engineers",
                "further_research": ["optimization"],
                "seo_friendly_keywords": ["one", "two"],
            }
        )

        with patch.object(
            mock_video_processor, "_invoke_openai_chat_structured_output"
        ) as mock_structured:
            mock_structured.return_value = structured_response

            summary_path = mock_video_processor.generate_summary(
                str(transcript_file),
                config={"output_format": "json", "include_keywords": False},
            )

        summary_file = Path(summary_path)
        payload = json.loads(summary_file.read_text(encoding="utf-8"))
        assert payload["key_points_covered"] == ["a", "b", "c", "d"]
        assert payload["seo_friendly_keywords"] == []
